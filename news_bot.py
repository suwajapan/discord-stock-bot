#!/usr/bin/env python3
"""
DiscordÊó•Êú¨Ê†™„Éã„É•„Éº„ÇπBot
ÊØéÊòº„ÄÅÊó•Êú¨Ê†™Èñ¢ÈÄ£„ÅÆ„Éã„É•„Éº„Çπ„Çí„Éî„ÉÉ„ÇØ„Ç¢„ÉÉ„Éó„Åó„Å¶Ë¶ÅÁ¥Ñ„Åó„ÄÅDiscord„Å´ÊäïÁ®ø„Åô„Çã
"""

import os
import sys
import re
from datetime import datetime
from typing import List, Dict

try:
    from zoneinfo import ZoneInfo
except ImportError:
    from backports.zoneinfo import ZoneInfo

import requests
import feedparser
from bs4 import BeautifulSoup
from openai import OpenAI


JST = ZoneInfo("Asia/Tokyo")


def fetch_google_news() -> List[Dict]:
    """Google News„Åã„ÇâÊó•Êú¨Ê†™Èñ¢ÈÄ£„Éã„É•„Éº„Çπ„ÇíÂèñÂæó"""
    news_items = []
    
    queries = [
        "Êó•Êú¨Ê†™",
        "Êó•ÁµåÂπ≥Âùá",
        "Êù±Ë®º",
    ]
    
    for query in queries:
        try:
            url = f"https://news.google.com/rss/search?q={query}&hl=ja&gl=JP&ceid=JP:ja"
            feed = feedparser.parse(url)
            
            for entry in feed.entries[:5]:
                title = entry.get("title", "")
                link = entry.get("link", "")
                source = entry.get("source", {}).get("title", "")
                
                if title and link:
                    news_items.append({
                        "title": title,
                        "link": link,
                        "source": source,
                        "origin": "Google News"
                    })
        except Exception as e:
            print(f"Error fetching Google News for '{query}': {e}", file=sys.stderr)
    
    return news_items


def fetch_yahoo_finance_news() -> List[Dict]:
    """Yahoo „Éï„Ç°„Ç§„Éä„É≥„Çπ„Åã„ÇâÊó•Êú¨Ê†™„Éã„É•„Éº„Çπ„ÇíÂèñÂæó"""
    news_items = []
    
    try:
        url = "https://finance.yahoo.co.jp/news/list/stock"
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
        }
        response = requests.get(url, headers=headers, timeout=15)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.text, "html.parser")
        
        articles = soup.select("a[href*='/news/detail/']")[:10]
        
        for article in articles:
            title = article.get_text(strip=True)
            link = article.get("href", "")
            
            if not link.startswith("http"):
                link = "https://finance.yahoo.co.jp" + link
            
            if title and len(title) > 10:
                news_items.append({
                    "title": title,
                    "link": link,
                    "source": "Yahoo „Éï„Ç°„Ç§„Éä„É≥„Çπ",
                    "origin": "Yahoo Finance"
                })
    except Exception as e:
        print(f"Error fetching Yahoo Finance news: {e}", file=sys.stderr)
    
    return news_items


def deduplicate_news(news_items: List[Dict]) -> List[Dict]:
    """ÈáçË§á„Éã„É•„Éº„Çπ„ÇíÈô§Âéª"""
    seen_titles = set()
    unique_items = []
    
    for item in news_items:
        title_normalized = re.sub(r'\s+', '', item["title"])[:30]
        
        if title_normalized not in seen_titles:
            seen_titles.add(title_normalized)
            unique_items.append(item)
    
    return unique_items


def summarize_news_with_ai(news_items: List[Dict], openai_key: str) -> str:
    """AI„Åß„Éã„É•„Éº„Çπ„ÇíË¶ÅÁ¥Ñ„ÉªÂàÜÊûê"""
    try:
        client = OpenAI(api_key=openai_key)
        
        news_text = "\n".join([
            f"- {item['title']}Ôºà{item['source']}Ôºâ"
            for item in news_items[:15]
        ])
        
        now = datetime.now(JST)
        weekday_jp = ["Êúà", "ÁÅ´", "Ê∞¥", "Êú®", "Èáë", "Âúü", "Êó•"][now.weekday()]
        
        prompt = f"""„ÅÇ„Å™„Åü„ÅØÊó•Êú¨Ê†™ÊäïË≥á„Ç≥„Éü„É•„Éã„ÉÜ„Ç£Âêë„Åë„ÅÆ„Éã„É•„Éº„Çπ„Ç≠„É•„É¨„Éº„Çø„Éº„Åß„Åô„ÄÇ
‰ª•‰∏ã„ÅÆÊú¨Êó•„ÅÆ„Éã„É•„Éº„Çπ‰∏ÄË¶ß„Åã„Çâ„ÄÅÊäïË≥áÂÆ∂„Å´„Å®„Å£„Å¶ÈáçË¶Å„Å™„Éã„É•„Éº„Çπ„Çí5„Äú7‰ª∂„Éî„ÉÉ„ÇØ„Ç¢„ÉÉ„Éó„Åó„ÄÅ
ÂàùÂøÉËÄÖ„Å´„ÇÇ„Çè„Åã„Çä„ÇÑ„Åô„ÅèË¶ÅÁ¥Ñ„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ

„ÄêÊú¨Êó•„Äë{now.strftime('%YÂπ¥%mÊúà%dÊó•')}Ôºà{weekday_jp}Ôºâ

„Äê„Éã„É•„Éº„Çπ‰∏ÄË¶ß„Äë
{news_text}

„ÄêÂá∫Âäõ„É´„Éº„É´„Äë
1. ÈáçË¶ÅÂ∫¶„ÅÆÈ´ò„ÅÑÈ†Ü„Å´5„Äú7‰ª∂„ÇíÈÅ∏ÂÆö
2. ÂêÑ„Éã„É•„Éº„Çπ„ÅØ1„Äú2Ë°å„ÅßÁ∞°ÊΩî„Å´Ë¶ÅÁ¥Ñ
3. „Å™„ÅúÊäïË≥áÂÆ∂„Å´„Å®„Å£„Å¶ÈáçË¶Å„Åã„ÇíÁ∞°ÊΩî„Å´Ë£úË∂≥
4. ÁµµÊñáÂ≠ó„ÇíÈÅ©Â∫¶„Å´‰ΩøÁî®„Åó„Å¶Ë™≠„Åø„ÇÑ„Åô„Åè
5. ÊúÄÂæå„Å´„Äåüìå Êú¨Êó•„ÅÆÊ≥®ÁõÆ„Éù„Ç§„É≥„Éà„Äç„Å®„Åó„Å¶1„Äú2Ë°å„Åß„Åæ„Å®„ÇÅ

„ÄêÂá∫Âäõ„Éï„Ç©„Éº„Éû„ÉÉ„Éà‰æã„Äë
1Ô∏è‚É£ **„Äá„Äá‰ºöÁ§æ„Åå‚ñ≥‚ñ≥„ÇíÁô∫Ë°®**
Ê±∫ÁÆóÂ•ΩË™ø„ÅßÊ†™‰æ°‰∏äÊòá„ÅÆÊùêÊñô„Å´„ÄÇÂçäÂ∞é‰ΩìÈñ¢ÈÄ£„Å´Ê≥®ÁõÆ„ÄÇ

2Ô∏è‚É£ **Êó•ÈäÄ„Åå‚ñ°‚ñ°„Å´„Å§„ÅÑ„Å¶Ë®ÄÂèä**
ÈáëËûçÊîøÁ≠ñ„ÅÆÂ§âÊõ¥Á§∫ÂîÜ„ÄÇÈäÄË°åÊ†™„Å´ÂΩ±Èüø„Åã„ÄÇ

ÔºàÁ∂ö„Åè...Ôºâ

üìå **Êú¨Êó•„ÅÆÊ≥®ÁõÆ„Éù„Ç§„É≥„Éà**
„Äú„Äú„Äú"""

        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "„ÅÇ„Å™„Åü„ÅØÊó•Êú¨Ê†™ÊäïË≥á„Ç≥„Éü„É•„Éã„ÉÜ„Ç£Âêë„Åë„Å´ÊØéÊó•„ÅÆ„Éã„É•„Éº„Çπ„Çí„Ç≠„É•„É¨„Éº„Ç∑„Éß„É≥„Åô„ÇãÂ∞ÇÈñÄÂÆ∂„Åß„Åô„ÄÇÂàùÂøÉËÄÖ„Åã„Çâ‰∏äÁ¥öËÄÖ„Åæ„ÅßÂΩπÁ´ã„Å§„ÄÅÊ≠£Á¢∫„ÅßÁ∞°ÊΩî„Å™Ë¶ÅÁ¥Ñ„ÇíÊèê‰æõ„Åó„Åæ„Åô„ÄÇ"},
                {"role": "user", "content": prompt}
            ],
            max_tokens=1000,
            temperature=0.5,
        )
        
        return response.choices[0].message.content.strip()
    
    except Exception as e:
        print(f"Error summarizing news: {e}", file=sys.stderr)
        return "„Éã„É•„Éº„Çπ„ÅÆË¶ÅÁ¥Ñ„ÇíÁîüÊàê„Åß„Åç„Åæ„Åõ„Çì„Åß„Åó„Åü„ÄÇ"


def format_message(summary: str) -> str:
    """DiscordÊäïÁ®øÁî®„ÅÆ„É°„ÉÉ„Çª„Éº„Ç∏„Çí„Éï„Ç©„Éº„Éû„ÉÉ„Éà"""
    now = datetime.now(JST)
    weekday_jp = ["Êúà", "ÁÅ´", "Ê∞¥", "Êú®", "Èáë", "Âúü", "Êó•"][now.weekday()]
    date_str = now.strftime(f"%mÊúà%dÊó•Ôºà{weekday_jp}Ôºâ")
    
    lines = [
        "üì∞ **Êó•Êú¨Ê†™„Éã„É•„Éº„Çπ„Åæ„Å®„ÇÅ**",
        f"üóìÔ∏è {date_str} 12:00 ÈÖç‰ø°",
        "",
        "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ",
        "",
        summary,
        "",
        "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ",
        "ÂçàÂæå„ÅÆ„Éà„É¨„Éº„Éâ„Å´„ÅäÂΩπÁ´ã„Å¶„Åè„Å†„Åï„ÅÑÔºÅüìä",
    ]
    
    return "\n".join(lines)


def send_to_discord(message: str, webhook_url: str) -> bool:
    """Discord„ÅÆWebhook„Å´„É°„ÉÉ„Çª„Éº„Ç∏„ÇíÈÄÅ‰ø°"""
    payload = {"content": message}
    
    try:
        response = requests.post(webhook_url, json=payload, timeout=30)
        response.raise_for_status()
        return True
    except requests.RequestException as e:
        print(f"Error sending to Discord: {e}", file=sys.stderr)
        return False


def main():
    webhook_url = os.environ.get("DISCORD_NEWS_WEBHOOK_URL")
    if not webhook_url:
        print("Error: DISCORD_NEWS_WEBHOOK_URL environment variable is not set", file=sys.stderr)
        sys.exit(1)
    
    openai_key = os.environ.get("OPENAI_API_KEY")
    if not openai_key:
        print("Error: OPENAI_API_KEY environment variable is not set", file=sys.stderr)
        sys.exit(1)
    
    print("Fetching news from Google News...")
    google_news = fetch_google_news()
    print(f"  Found {len(google_news)} articles")
    
    print("Fetching news from Yahoo Finance...")
    yahoo_news = fetch_yahoo_finance_news()
    print(f"  Found {len(yahoo_news)} articles")
    
    all_news = google_news + yahoo_news
    unique_news = deduplicate_news(all_news)
    print(f"Total unique articles: {len(unique_news)}")
    
    if not unique_news:
        print("Error: No news articles found", file=sys.stderr)
        sys.exit(1)
    
    print("Summarizing news with AI...")
    summary = summarize_news_with_ai(unique_news, openai_key)
    
    message = format_message(summary)
    print("Message to send:")
    print(message)
    print("-" * 40)
    
    if send_to_discord(message, webhook_url):
        print("Successfully sent to Discord!")
    else:
        print("Failed to send to Discord.", file=sys.stderr)
        sys.exit(1)


if __name__ == "__main__":
    main()
